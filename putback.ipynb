{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "putback.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUYQPzIrMvui+uHoQCwgvv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SylviaaaaW/StyleCLIP_study/blob/main/putback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/1にStyleCLIPから得る表情\n",
        "/content/getに元の画像とshape_predictor_68_face_landmarks.dat\n",
        "/content/outputに結果を保存\n",
        "output.mp4,outut.zipを出力"
      ],
      "metadata": {
        "id": "ViQkFsi8F-z2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRS7BNgxx9T2",
        "outputId": "ec3dea32-c51a-4bb7-cb09-f7b2110fa4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "000000.png\n",
            "000001.png\n",
            "000002.png\n",
            "000003.png\n",
            "000004.png\n",
            "000005.png\n",
            "000006.png\n",
            "000007.png\n",
            "000008.png\n",
            "000009.png\n",
            "000010.png\n",
            "000011.png\n",
            "000012.png\n",
            "000013.png\n",
            "000014.png\n",
            "000015.png\n",
            "000016.png\n",
            "000017.png\n",
            "000018.png\n",
            "000019.png\n",
            "000020.png\n",
            "000021.png\n",
            "000022.png\n",
            "000023.png\n",
            "000024.png\n",
            "000025.png\n",
            "000026.png\n",
            "000027.png\n",
            "000028.png\n",
            "000029.png\n",
            "000030.png\n",
            "000031.png\n",
            "000032.png\n",
            "000033.png\n",
            "000034.png\n",
            "000035.png\n",
            "000036.png\n",
            "000037.png\n",
            "000038.png\n",
            "000039.png\n",
            "000040.png\n",
            "000041.png\n",
            "000042.png\n",
            "000043.png\n",
            "000044.png\n",
            "000045.png\n",
            "000046.png\n",
            "000047.png\n",
            "000048.png\n",
            "000049.png\n",
            "000050.png\n",
            "000051.png\n",
            "000052.png\n",
            "000053.png\n",
            "000054.png\n",
            "000055.png\n",
            "000056.png\n",
            "000057.png\n",
            "000058.png\n",
            "000059.png\n",
            "000060.png\n",
            "000061.png\n",
            "000062.png\n",
            "000063.png\n",
            "000064.png\n",
            "000065.png\n",
            "000066.png\n",
            "000067.png\n",
            "000068.png\n",
            "000069.png\n",
            "000070.png\n",
            "000071.png\n",
            "000072.png\n",
            "000073.png\n",
            "000074.png\n",
            "000075.png\n",
            "000076.png\n",
            "000077.png\n",
            "000078.png\n",
            "000079.png\n",
            "000080.png\n",
            "000081.png\n",
            "000082.png\n",
            "000083.png\n",
            "000084.png\n",
            "000085.png\n",
            "000086.png\n",
            "000087.png\n",
            "000088.png\n",
            "000089.png\n",
            "000090.png\n",
            "000091.png\n",
            "000092.png\n",
            "000093.png\n",
            "000094.png\n",
            "000095.png\n",
            "000096.png\n",
            "000097.png\n",
            "000098.png\n",
            "000099.png\n",
            "000100.png\n",
            "000101.png\n",
            "000102.png\n",
            "000103.png\n",
            "000104.png\n",
            "000105.png\n",
            "000106.png\n",
            "000107.png\n",
            "000108.png\n",
            "000109.png\n",
            "000110.png\n",
            "000111.png\n",
            "000112.png\n",
            "000113.png\n",
            "000114.png\n",
            "000115.png\n",
            "000116.png\n",
            "000117.png\n",
            "000118.png\n",
            "000119.png\n",
            "000120.png\n",
            "000121.png\n",
            "000122.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy\n",
        "\n",
        "import shutil\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# !/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "PREDICTOR_PATH = \"/content/get/shape_predictor_68_face_landmarks.dat\"# モデル\n",
        "SCALE_FACTOR = 1\n",
        "FEATHER_AMOUNT = 11\n",
        "\n",
        "FACE_POINTS = list(range(17, 68))\n",
        "MOUTH_POINTS = list(range(48, 61))\n",
        "RIGHT_BROW_POINTS = list(range(17, 22))\n",
        "LEFT_BROW_POINTS = list(range(22, 27))\n",
        "RIGHT_EYE_POINTS = list(range(36, 42))\n",
        "LEFT_EYE_POINTS = list(range(42, 48))\n",
        "NOSE_POINTS = list(range(27, 35))\n",
        "JAW_POINTS = list(range(0, 17))\n",
        "\n",
        "# Points used to line up the images.\n",
        "ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS +\n",
        "                RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)\n",
        "\n",
        "# Points from the second image to overlay on the first. The convex hull of each\n",
        "# element will be overlaid.\n",
        "OVERLAY_POINTS = [\n",
        "    LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
        "    NOSE_POINTS + MOUTH_POINTS,\n",
        "]\n",
        "\n",
        "# Amount of blur to use during colour correction, as a fraction of the\n",
        "# pupillary distance.\n",
        "COLOUR_CORRECT_BLUR_FRAC = 0.6\n",
        "\n",
        "#dlibでランドマークを検出\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
        "\n",
        "\n",
        "class TooManyFaces(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class NoFaces(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def get_landmarks(im):\n",
        "    rects = detector(im, 1) #顔検出\n",
        "\n",
        "    if len(rects) > 1:\n",
        "        raise TooManyFaces #顔が複数\n",
        "    if len(rects) == 0:\n",
        "        raise NoFaces\n",
        "\n",
        "    return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()]) #顔の輪郭\n",
        "\n",
        "\n",
        "def annotate_landmarks(im, landmarks):\n",
        "    im = im.copy()\n",
        "    for idx, point in enumerate(landmarks):\n",
        "        pos = (point[0, 0], point[0, 1])\n",
        "        cv2.putText(im, str(idx), pos,\n",
        "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
        "                    fontScale=0.4,\n",
        "                    color=(0, 0, 255))\n",
        "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
        "    return im\n",
        "\n",
        "# 図２ー＞図1\n",
        "def draw_convex_hull(im, points, color):\n",
        "    points = cv2.convexHull(points) # 凸包を探す\n",
        "    cv2.fillConvexPoly(im, points, color=color) # 凸包を埋める\n",
        "\n",
        "\n",
        "# get_face_mask()\n",
        "def get_face_mask(im, landmarks):\n",
        "    im = numpy.zeros(im.shape[:2], dtype=numpy.float64) # 定制数据类型\n",
        "\n",
        "    for group in OVERLAY_POINTS:\n",
        "        draw_convex_hull(im,\n",
        "                         landmarks[group],\n",
        "                         color=1)\n",
        "\n",
        "    # array([[[0, 1, 2],\n",
        "    #         [3, 4, 5]],\n",
        "    #\n",
        "    #        [[6, 7, 8],\n",
        "    #         [9, 10, 11]]])\n",
        "    #\n",
        "    # In[61]: arr1.shape  # \n",
        "    # Out[61]: (2, 2, 3)  # \n",
        "    # In[62]: arr1.transpose((1, 0, 2))\n",
        "    # Out[62]:\n",
        "    # array([[[0, 1, 2],\n",
        "    #         [6, 7, 8]],\n",
        "    #\n",
        "    #        [[3, 4, 5],\n",
        "    #         [9, 10, 11]]])\n",
        "\n",
        "    im = numpy.array([im, im, im]).transpose((1, 2, 0))\n",
        "\n",
        "    im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
        "    im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
        "\n",
        "    return im\n",
        "\n",
        "#Procrustes Analysi\n",
        "def transformation_from_points(points1, points2): \n",
        "    '''\n",
        "    Return an affine transformation [s * R | T] such that:\n",
        "        sum ||s*R*p1,i + T - p2,i||^2\n",
        "    is minimized.\n",
        "\n",
        "    R：2x2 直交行列\n",
        "    s：スカラー\n",
        "    T：二次元ベクトル\n",
        "    pi 、qi\n",
        "    Ordinary Procrustes Analysis'''\n",
        "\n",
        "    points1 = points1.astype(numpy.float64) # \n",
        "    points2 = points2.astype(numpy.float64)\n",
        "\n",
        "    c1 = numpy.mean(points1, axis=0) \n",
        "    c2 = numpy.mean(points2, axis=0)\n",
        "    points1 -= c1\n",
        "    points2 -= c2\n",
        "\n",
        "    s1 = numpy.std(points1) # 標準の差\n",
        "    s2 = numpy.std(points2)\n",
        "    points1 /= s1 #\n",
        "    points2 /= s2\n",
        "\n",
        "    U, S, Vt = numpy.linalg.svd(points1.T * points2) # singular value decomposition\n",
        "    R = (U * Vt).T #\n",
        "\n",
        "    return numpy.vstack([numpy.hstack(((s2 / s1) * R,\n",
        "                                       c2.T - (s2 / s1) * R * c1.T)),\n",
        "                         numpy.matrix([0., 0., 1.])])\n",
        "\n",
        "\n",
        "def read_im_and_landmarks(fname): \n",
        "    # 図を読み込み\n",
        "    # 関数cv2.imread()\n",
        "    # cv2.IMREAD_COLOR：画像をカラー(RGB)で読込む　画像の透明度は無視される．デフォルト値\n",
        "    # cv2.IMREAD_GRAYSCALE：グレースケール画像として読み込む\n",
        "    #\n",
        "    # import cv2\n",
        "    # img = cv2.imread('lena.jpg', 0)\n",
        "    \n",
        "    im = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
        "    #im = cv2.imread(file_pathname+'/'+fname, cv2.IMREAD_COLOR)\n",
        "    # import cv2\n",
        "    # image = cv2.imread(\"D:/shape.bmp\")\n",
        "    # print(image.shape[0])\n",
        "    # print(image.shape[1])\n",
        "    # print(image.shape[2])\n",
        "    # 結果\n",
        "    # 300\n",
        "    # 200\n",
        "    # 3\n",
        "    # shape.bmp　200ピクセル*300ピクセル　カラー\n",
        "    im = cv2.resize(im, (im.shape[1] * SCALE_FACTOR,\n",
        "                         im.shape[0] * SCALE_FACTOR))\n",
        "    s = get_landmarks(im)\n",
        "\n",
        "    return im, s\n",
        "\n",
        "\n",
        "def warp_im(im, M, dshape):\n",
        "    output_im = numpy.zeros(dshape, dtype=im.dtype)\n",
        "    cv2.warpAffine(im,\n",
        "                   M[:2],\n",
        "                   (dshape[1], dshape[0]),\n",
        "                   dst=output_im,\n",
        "                   borderMode=cv2.BORDER_TRANSPARENT,\n",
        "                   flags=cv2.WARP_INVERSE_MAP)\n",
        "    return output_im\n",
        "\n",
        "# 画像の肌色、照明の違いを修正\n",
        "def correct_colours(im1, im2, landmarks1):\n",
        "    # blur_amount\n",
        "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * numpy.linalg.norm(\n",
        "        numpy.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
        "        numpy.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
        "    blur_amount = int(blur_amount)\n",
        "    if blur_amount % 2 == 0:\n",
        "        blur_amount += 1\n",
        "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
        "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
        "\n",
        "    # \n",
        "    im2_blur += (128 * (im2_blur <= 1.0)).astype(im2_blur.dtype)\n",
        "\n",
        "    return (im2.astype(numpy.float64) * im1_blur.astype(numpy.float64) /\n",
        "            im2_blur.astype(numpy.float64))\n",
        "\n",
        "\n",
        "#cnt = 123\n",
        "for i in range(0,123):\n",
        "  input_img= str(i).zfill(6)+\".png\"\n",
        "  input_path=\"/content/1/\"+input_img\n",
        "  print(input_img)\n",
        "\n",
        "  #sys.argvプログラム名称、背景図のpath、表情変化後の図のpath。\n",
        "  sys.argv = [\"SwapFace.py\", \"/content/get/000019.jpg\", input_path]\n",
        "  im1, landmarks1 = read_im_and_landmarks(sys.argv[1])\n",
        "  im2, landmarks2 = read_im_and_landmarks(sys.argv[2])\n",
        "\n",
        "  M = transformation_from_points(landmarks1[ALIGN_POINTS],\n",
        "                                 landmarks2[ALIGN_POINTS])\n",
        "\n",
        "  mask = get_face_mask(im2, landmarks2)\n",
        "  warped_mask = warp_im(mask, M, im1.shape)\n",
        "  combined_mask = numpy.max([get_face_mask(im1, landmarks1), warped_mask],\n",
        "                            axis=0)\n",
        "\n",
        "  warped_im2 = warp_im(im2, M, im1.shape)\n",
        "  warped_corrected_im2 = correct_colours(im1, warped_im2, landmarks1)\n",
        "\n",
        "  output_im = im1 * (1.0 - combined_mask) + warped_corrected_im2 * combined_mask\n",
        "\n",
        "  #output_name=input_img +'.png'\n",
        "  \n",
        "  if os.path.exists('./output' + input_img + '.png'):\n",
        "   os.remove('./output' + input_name + '.png')\n",
        "\n",
        "  cv2.imwrite('/content/output/'+input_img, output_im)\n",
        "  i+=1\n",
        " \n",
        "\n",
        "\n",
        "#input_img=\"000017.png\"\n",
        "#input_path=\"/content/1/\"+input_img\n",
        "# sys.argvプログラム名称、背景図のpath、表情変化後の図のpath。\n",
        "#sys.argv = [\"SwapFace.py\", \"/content/get/195081.jpg\", input_name]\n",
        "\n",
        "#im1, landmarks1 = read_im_and_landmarks(sys.argv[1])\n",
        "#im2, landmarks2 = read_im_and_landmarks(sys.argv[2])\n",
        "\n",
        "#M = transformation_from_points(landmarks1[ALIGN_POINTS],\n",
        "#                               landmarks2[ALIGN_POINTS])\n",
        "\n",
        "#mask = get_face_mask(im2, landmarks2)\n",
        "#warped_mask = warp_im(mask, M, im1.shape)\n",
        "#combined_mask = numpy.max([get_face_mask(im1, landmarks1), warped_mask],\n",
        "#                          axis=0)\n",
        "\n",
        "#warped_im2 = warp_im(im2, M, im1.shape)\n",
        "#warped_corrected_im2 = correct_colours(im1, warped_im2, landmarks1)\n",
        "\n",
        "#output_im = im1 * (1.0 - combined_mask) + warped_corrected_im2 * combined_mask\n",
        "\n",
        "#output_name=input_name +'.png'\n",
        "#cv2.imwrite('/content/output'+input_img, output_im)\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/output.zip /content/output\n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "! ffmpeg -r 30 -i output/%6d.png\\\n",
        "               -vcodec libx264 -pix_fmt yuv420p output.mp4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTgFzDLaAfJt",
        "outputId": "db5e3b1d-6b3a-435a-9550-6443fa6f8acc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/000026.png (deflated 2%)\n",
            "  adding: content/output/000100.png (deflated 2%)\n",
            "  adding: content/output/000067.png (deflated 2%)\n",
            "  adding: content/output/000058.png (deflated 2%)\n",
            "  adding: content/output/000066.png (deflated 2%)\n",
            "  adding: content/output/000076.png (deflated 2%)\n",
            "  adding: content/output/000060.png (deflated 2%)\n",
            "  adding: content/output/000095.png (deflated 2%)\n",
            "  adding: content/output/000082.png (deflated 2%)\n",
            "  adding: content/output/000079.png (deflated 2%)\n",
            "  adding: content/output/000051.png (deflated 2%)\n",
            "  adding: content/output/000040.png (deflated 2%)\n",
            "  adding: content/output/000055.png (deflated 2%)\n",
            "  adding: content/output/000005.png (deflated 2%)\n",
            "  adding: content/output/000071.png (deflated 2%)\n",
            "  adding: content/output/000043.png (deflated 2%)\n",
            "  adding: content/output/000034.png (deflated 2%)\n",
            "  adding: content/output/000074.png (deflated 2%)\n",
            "  adding: content/output/000020.png (deflated 2%)\n",
            "  adding: content/output/000003.png (deflated 2%)\n",
            "  adding: content/output/000037.png (deflated 2%)\n",
            "  adding: content/output/000009.png (deflated 2%)\n",
            "  adding: content/output/000105.png (deflated 2%)\n",
            "  adding: content/output/000007.png (deflated 2%)\n",
            "  adding: content/output/000083.png (deflated 2%)\n",
            "  adding: content/output/000068.png (deflated 2%)\n",
            "  adding: content/output/000063.png (deflated 2%)\n",
            "  adding: content/output/000091.png (deflated 2%)\n",
            "  adding: content/output/000014.png (deflated 2%)\n",
            "  adding: content/output/000085.png (deflated 2%)\n",
            "  adding: content/output/000038.png (deflated 2%)\n",
            "  adding: content/output/000097.png (deflated 2%)\n",
            "  adding: content/output/000045.png (deflated 2%)\n",
            "  adding: content/output/000044.png (deflated 2%)\n",
            "  adding: content/output/000032.png (deflated 2%)\n",
            "  adding: content/output/000022.png (deflated 2%)\n",
            "  adding: content/output/000103.png (deflated 2%)\n",
            "  adding: content/output/000012.png (deflated 2%)\n",
            "  adding: content/output/000101.png (deflated 2%)\n",
            "  adding: content/output/000122.png (deflated 2%)\n",
            "  adding: content/output/000046.png (deflated 2%)\n",
            "  adding: content/output/000033.png (deflated 2%)\n",
            "  adding: content/output/000018.png (deflated 1%)\n",
            "  adding: content/output/000015.png (deflated 2%)\n",
            "  adding: content/output/000080.png (deflated 2%)\n",
            "  adding: content/output/000094.png (deflated 2%)\n",
            "  adding: content/output/000112.png (deflated 2%)\n",
            "  adding: content/output/000099.png (deflated 2%)\n",
            "  adding: content/output/000054.png (deflated 2%)\n",
            "  adding: content/output/000053.png (deflated 2%)\n",
            "  adding: content/output/000017.png (deflated 2%)\n",
            "  adding: content/output/000075.png (deflated 2%)\n",
            "  adding: content/output/000013.png (deflated 2%)\n",
            "  adding: content/output/000102.png (deflated 2%)\n",
            "  adding: content/output/000081.png (deflated 2%)\n",
            "  adding: content/output/000104.png (deflated 2%)\n",
            "  adding: content/output/000117.png (deflated 2%)\n",
            "  adding: content/output/000048.png (deflated 2%)\n",
            "  adding: content/output/000047.png (deflated 2%)\n",
            "  adding: content/output/000021.png (deflated 2%)\n",
            "  adding: content/output/000059.png (deflated 2%)\n",
            "  adding: content/output/000052.png (deflated 2%)\n",
            "  adding: content/output/000036.png (deflated 2%)\n",
            "  adding: content/output/000064.png (deflated 2%)\n",
            "  adding: content/output/000114.png (deflated 2%)\n",
            "  adding: content/output/000006.png (deflated 2%)\n",
            "  adding: content/output/000078.png (deflated 2%)\n",
            "  adding: content/output/000089.png (deflated 2%)\n",
            "  adding: content/output/000001.png (deflated 2%)\n",
            "  adding: content/output/000029.png (deflated 2%)\n",
            "  adding: content/output/000072.png (deflated 2%)\n",
            "  adding: content/output/000028.png (deflated 2%)\n",
            "  adding: content/output/000121.png (deflated 2%)\n",
            "  adding: content/output/000049.png (deflated 2%)\n",
            "  adding: content/output/000086.png (deflated 2%)\n",
            "  adding: content/output/000062.png (deflated 1%)\n",
            "  adding: content/output/000106.png (deflated 2%)\n",
            "  adding: content/output/000093.png (deflated 2%)\n",
            "  adding: content/output/000092.png (deflated 2%)\n",
            "  adding: content/output/000116.png (deflated 2%)\n",
            "  adding: content/output/000098.png (deflated 2%)\n",
            "  adding: content/output/000000.png (deflated 2%)\n",
            "  adding: content/output/000108.png (deflated 2%)\n",
            "  adding: content/output/000035.png (deflated 2%)\n",
            "  adding: content/output/000016.png (deflated 2%)\n",
            "  adding: content/output/000087.png (deflated 2%)\n",
            "  adding: content/output/000096.png (deflated 2%)\n",
            "  adding: content/output/000025.png (deflated 2%)\n",
            "  adding: content/output/000056.png (deflated 2%)\n",
            "  adding: content/output/000107.png (deflated 2%)\n",
            "  adding: content/output/000118.png (deflated 2%)\n",
            "  adding: content/output/000010.png (deflated 2%)\n",
            "  adding: content/output/000008.png (deflated 2%)\n",
            "  adding: content/output/000057.png (deflated 2%)\n",
            "  adding: content/output/000011.png (deflated 2%)\n",
            "  adding: content/output/000070.png (deflated 2%)\n",
            "  adding: content/output/000120.png (deflated 2%)\n",
            "  adding: content/output/000024.png (deflated 2%)\n",
            "  adding: content/output/000077.png (deflated 2%)\n",
            "  adding: content/output/000031.png (deflated 2%)\n",
            "  adding: content/output/000109.png (deflated 2%)\n",
            "  adding: content/output/000019.png (deflated 2%)\n",
            "  adding: content/output/000073.png (deflated 2%)\n",
            "  adding: content/output/000115.png (deflated 2%)\n",
            "  adding: content/output/000088.png (deflated 2%)\n",
            "  adding: content/output/000027.png (deflated 2%)\n",
            "  adding: content/output/000090.png (deflated 2%)\n",
            "  adding: content/output/000042.png (deflated 2%)\n",
            "  adding: content/output/000084.png (deflated 2%)\n",
            "  adding: content/output/000004.png (deflated 2%)\n",
            "  adding: content/output/000023.png (deflated 2%)\n",
            "  adding: content/output/000041.png (deflated 2%)\n",
            "  adding: content/output/000030.png (deflated 2%)\n",
            "  adding: content/output/000069.png (deflated 2%)\n",
            "  adding: content/output/000050.png (deflated 2%)\n",
            "  adding: content/output/000111.png (deflated 2%)\n",
            "  adding: content/output/000002.png (deflated 2%)\n",
            "  adding: content/output/000039.png (deflated 2%)\n",
            "  adding: content/output/000110.png (deflated 2%)\n",
            "  adding: content/output/000065.png (deflated 2%)\n",
            "  adding: content/output/000119.png (deflated 2%)\n",
            "  adding: content/output/000113.png (deflated 2%)\n",
            "  adding: content/output/000061.png (deflated 2%)\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from 'output/%6d.png':\n",
            "  Duration: 00:00:04.92, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 178x218, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mprofile High, level 1.2\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'output.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 178x218, q=-1--1, 30 fps, 15360 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "frame=  123 fps=0.0 q=-1.0 Lsize=      14kB time=00:00:04.00 bitrate=  27.9kbits/s speed=14.6x    \n",
            "video:11kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 19.730171%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mframe I:1     Avg QP:20.27  size:  6927\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mframe P:32    Avg QP:22.47  size:    83\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mframe B:90    Avg QP:31.36  size:    15\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mconsecutive B-frames:  0.8%  3.3%  4.9% 91.1%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mmb I  I16..4:  1.8% 88.1% 10.1%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mmb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  3.7%  1.5%  1.3%  0.0%  0.0%    skip:93.6%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.1%  0.0%  0.0%  direct: 0.0%  skip:98.9%  L0:21.4% L1:76.8% BI: 1.8%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0m8x8 transform intra:88.1% inter:40.6%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mcoded y,uvDC,uvAC intra: 95.5% 97.0% 76.2% inter: 0.5% 0.4% 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mi16 v,h,dc,p:  0%  0% 100%  0%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 13%  7%  4%  8% 15%  5% 13%  7%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu:  9% 44%  6%  3%  7%  5% 12%  4% 10%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mi8c dc,h,v,p: 44% 26% 24%  6%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mref P L0: 78.3% 10.3%  9.5%  1.9%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mref B L0: 69.2% 25.6%  5.1%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mref B L1: 93.9%  6.1%\n",
            "\u001b[1;36m[libx264 @ 0x5627b3059e00] \u001b[0mkb/s:21.36\n"
          ]
        }
      ]
    }
  ]
}